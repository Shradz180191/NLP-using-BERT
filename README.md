# NLP-using-BERT

https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270

https://github.com/google-research/bert

https://medium.com/dair-ai/pytorch-transformers-welcomes-roberta-39aeb8d9d17a // PyTorch Transformers welcomes RoBERTa

https://explosion.ai/blog/spacy-pytorch-transformers?utm_source=quora&utm_medium=referral // spaCy meets PyTorch-Transformers: Fine-tune BERT, XLNet and GPT-2

https://medium.com/orb-engineering/naacl-19-notes-practical-insights-for-natural-language-processing-applications-part-i-5f981c92af80?utm_source=quora&utm_medium=referral // NAACL ’19 Notes: Practical Insights for Natural Language Processing Applications — Part I

https://docs.google.com/presentation/d/1fIhGikFPnb7G5kr58OvYC3GN4io7MznnM0aAgadvJfc/edit // Transfer learning in NLP
